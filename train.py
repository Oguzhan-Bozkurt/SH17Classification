import sys
import os
import time
import gc
import shutil
import argparse
import pandas as pd
from pathlib import Path
from dataclasses import dataclass, field
from typing import List

try:
    from ultralytics import YOLO
    import torch
except ImportError:
    print("âŒ Eksik kÃ¼tÃ¼phane: pip install ultralytics pandas")
    sys.exit(1)

# ============================================================================
# CONFIGURATION
# ============================================================================
os.environ['CUDNN_BENCHMARK'] = '1'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'garbage_collection_threshold:0.8,max_split_size_mb:128'

@dataclass
class Config:
    # Dinamik path'ler - Ã§alÄ±ÅŸtÄ±rma sÄ±rasÄ±nda ayarlanacak
    project_root: str = None
    images_dir: str = None
    
    # Dataset SÄ±nÄ±f SÄ±ralamasÄ±
    class_names: List[str] = field(default_factory=lambda: [
        "person", "ear", "ear-mufs", "face", "face-guard", "face-mask",
        "foot", "tool", "glasses", "gloves", "helmet", "hands", "head",
        "medical-suit", "shoes", "safety-suit", "safety-vest"
    ])
    
    imgsz: int = 640
    batch_size: int = 64  # A5000
    workers: int = 64     # HÄ±z iÃ§in
    cache_images: bool = True # RAM Cache AÃ‡IK

# ============================================================================
# UTILITIES
# ============================================================================
def prepare_dataset(cfg):
    root = Path(cfg.project_root)
    img_dir = Path(cfg.images_dir)
    new_files = {}
    print("\nğŸ› ï¸ Dataset HazÄ±rlanÄ±yor...")
    print(f"ğŸ“ Proje Dizini: {root}")
    print(f"ğŸ–¼ï¸ GÃ¶rsel Dizini: {img_dir}")
    
    for split in ['train', 'val', 'test']:
        txt = root / f"{split}.txt"
        abs_txt = root / f"{split}_abs.txt"
        if txt.exists():
            with open(txt, 'r') as f: lines = [l.strip() for l in f.readlines() if l.strip()]
            valid = []
            missing = 0
            for l in lines:
                p = Path(l)
                full = img_dir / p.name
                if full.exists(): 
                    valid.append(str(full.absolute()))
                elif p.exists(): 
                    valid.append(str(p.absolute()))
                else:
                    missing += 1
            with open(abs_txt, 'w') as f: f.write('\n'.join(valid))
            new_files[split] = str(abs_txt.absolute())
            print(f"   âœ… {split}: {len(valid)} dosya bulundu" + (f", {missing} eksik" if missing else ""))

    yaml_path = root / "sh17_single.yaml"
    with open(yaml_path, 'w') as f:
        for k, v in new_files.items(): f.write(f"{k}: {v}\n")
        f.write("\nnames:\n")
        for i, n in enumerate(cfg.class_names): f.write(f"  {i}: {n}\n")
    return yaml_path

def save_report(model_name, metrics, duration, total_epochs, save_dir):
    rows = []
    try:
        p = metrics.box.p
        r = metrics.box.r
        f1 = metrics.box.f1
        map50 = metrics.box.all_ap[:, 0]
        map95 = metrics.box.all_ap.mean(1)
        for i, name in metrics.names.items():
            rows.append({
                "Class": name, "Precision": round(p[i], 4), "Recall": round(r[i], 4),
                "F1-Score": round(f1[i], 4), "mAP@0.5": round(map50[i], 4), "mAP@0.5:0.95": round(map95[i], 4),
                "Duration_Min": ""
            })
    except: pass
    
    summary = {
        "Class": "TOTAL_SUMMARY",
        "Precision": round(metrics.box.mp, 4), "Recall": round(metrics.box.mr, 4),
        "F1-Score": round(metrics.box.f1.mean(), 4), "mAP@0.5": round(metrics.box.map50, 4), 
        "mAP@0.5:0.95": round(metrics.box.map, 4), "Duration_Min": round(duration, 2)
    }
    df = pd.DataFrame(rows + [summary])
    
    out_dir = Path(save_dir) / "reports"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / f"{model_name}_{total_epochs}ep_report.csv"
    df.to_csv(out_path, index=False)
    print(f"ğŸ“Š Rapor Kaydedildi: {out_path}")

def force_patch_workers(ckpt_path):
    try:
        ckpt = torch.load(ckpt_path, map_location='cpu')
        if 'train_args' in ckpt and isinstance(ckpt['train_args'], dict):
            ckpt['train_args']['workers'] = 0
            torch.save(ckpt, ckpt_path)
            return True
    except: pass
    return False

def select_model_menu():
    models = [
        # YOLOv10 Serisi
        {"name": "yolov10n", "file": "yolov10n.pt"},
        {"name": "yolov10s", "file": "yolov10s.pt"},
        {"name": "yolov10m", "file": "yolov10m.pt"},
        {"name": "yolov10b", "file": "yolov10b.pt"},
        {"name": "yolov10l", "file": "yolov10l.pt"},
        {"name": "yolov10x", "file": "yolov10x.pt"},
        # YOLO11 Serisi
        {"name": "yolo11n", "file": "yolo11n.pt"},
        {"name": "yolo11s", "file": "yolo11s.pt"},
        {"name": "yolo11m", "file": "yolo11m.pt"},
        {"name": "yolo11l", "file": "yolo11l.pt"},
        {"name": "yolo11x", "file": "yolo11x.pt"},
        # YOLO12 Serisi
        {"name": "yolo12n", "file": "yolo12n.pt"},
        {"name": "yolo12s", "file": "yolo12s.pt"},
        {"name": "yolo12m", "file": "yolo12m.pt"},
        {"name": "yolo12l", "file": "yolo12l.pt"},
        {"name": "yolo12x", "file": "yolo12x.pt"},
    ]
    print("\n" + "=" * 40)
    print("MODEL SEÃ‡Ä°MÄ°")
    print("=" * 40)
    print("\nğŸ“¦ YOLOv10 Serisi:")
    for i, m in enumerate(models[:6], 1):
        status = "âœ…" if os.path.exists(m['file']) else "â¬‡ï¸"
        print(f"  {i:2}. {m['name']:<12} {status}")
    print("\nğŸ“¦ YOLO11 Serisi:")
    for i, m in enumerate(models[6:11], 7):
        status = "âœ…" if os.path.exists(m['file']) else "â¬‡ï¸"
        print(f"  {i:2}. {m['name']:<12} {status}")
    print("\nğŸ“¦ YOLO12 Serisi:")
    for i, m in enumerate(models[11:], 12):
        status = "âœ…" if os.path.exists(m['file']) else "â¬‡ï¸"
        print(f"  {i:2}. {m['name']:<12} {status}")
    
    while True:
        try:
            sel = int(input("\nModel NumarasÄ± Girin: ").strip())
            if 1 <= sel <= len(models):
                return models[sel-1]['name']
            print("âŒ GeÃ§ersiz numara.")
        except ValueError:
            print("âŒ LÃ¼tfen sayÄ± girin.")

# ============================================================================
# MAIN TRAINING LOGIC
# ============================================================================
def parse_args():
    parser = argparse.ArgumentParser(description='SH17 YOLO EÄŸitim AracÄ±')
    parser.add_argument('--project-root', type=str, 
                        default=os.environ.get('SH17_PROJECT_ROOT', '.'),
                        help='Proje ana dizini (train.txt, val.txt burada)')
    parser.add_argument('--images-dir', type=str,
                        default=os.environ.get('SH17_IMAGES_DIR', None),
                        help='GÃ¶rsellerin bulunduÄŸu dizin (varsayÄ±lan: project_root/data/images)')
    parser.add_argument('--checkpoints', type=str, default=None,
                        help='Checkpoint listesi, virgÃ¼lle ayrÄ±lmÄ±ÅŸ (Ã¶rn: 25,50,100,200)')
    parser.add_argument('--model', type=str, default=None,
                        help='Model adÄ± (Ã¶rn: yolo12x) - interaktif menÃ¼yÃ¼ atlar')
    parser.add_argument('--overwrite', action='store_true',
                        help='SÄ±fÄ±rdan baÅŸla (eski eÄŸitimi sil)')
    return parser.parse_args()

def get_current_epoch(last_pt_path):
    """Checkpoint dosyasÄ±ndan mevcut epoch'u oku"""
    try:
        ckpt = torch.load(last_pt_path, map_location='cpu')
        return ckpt.get('epoch', -1) + 1
    except:
        return 0

def run_validation_and_report(model_path, yaml_path, cfg, model_name, epoch, result_dir, ckpt_dir, duration):
    """Validation Ã§alÄ±ÅŸtÄ±r ve rapor kaydet"""
    print(f"\n{'='*50}")
    print(f"ğŸ“Š CHECKPOINT {epoch} - Validation & Rapor")
    print(f"{'='*50}")
    
    gc.collect()
    torch.cuda.empty_cache()
    
    val_model = YOLO(str(model_path))
    metrics = val_model.val(data=str(yaml_path), device=0, batch=cfg.batch_size, workers=0, verbose=False)
    
    save_report(model_name, metrics, duration, epoch, str(result_dir))
    
    # Checkpoint'i kaydet
    dest_pt = ckpt_dir / f"{model_name}_{epoch}ep.pt"
    shutil.copy(model_path, dest_pt)
    print(f"ğŸ’¾ Checkpoint Kaydedildi: {dest_pt}")
    
    del val_model
    gc.collect()
    torch.cuda.empty_cache()
    
    return metrics

def train_to_checkpoint(model, yaml_path, cfg, model_name, target_epoch, workers, is_first_run=False):
    """Belirli bir epoch'a kadar eÄŸit"""
    print(f"\nğŸ¯ Hedef Epoch: {target_epoch}")
    
    model.train(
        data=str(yaml_path),
        epochs=target_epoch,
        imgsz=cfg.imgsz,
        batch=cfg.batch_size,
        workers=workers,
        device=0,
        project="runs/detect",
        name=model_name,
        exist_ok=True,
        resume=not is_first_run,  # Ä°lk Ã§alÄ±ÅŸtÄ±rma deÄŸilse resume=True
        cache=cfg.cache_images if is_first_run else False,  # Cache sadece ilk seferde
        patience=0  # Early stopping kapalÄ± (checkpoint'lere ulaÅŸmak iÃ§in)
    )

def main():
    args = parse_args()
    
    # Config oluÅŸtur ve path'leri ayarla
    cfg = Config()
    cfg.project_root = os.path.abspath(args.project_root)
    cfg.images_dir = args.images_dir or os.path.join(cfg.project_root, 'data', 'images')
    
    # Path'leri doÄŸrula
    if not os.path.isdir(cfg.images_dir):
        print(f"âŒ HATA: GÃ¶rsel dizini bulunamadÄ±: {cfg.images_dir}")
        sys.exit(1)
    
    yaml_path = prepare_dataset(cfg)
    
    result_dir = Path("SH17_Results_Single")
    ckpt_dir = result_dir / "checkpoints"
    ckpt_dir.mkdir(parents=True, exist_ok=True)

    print("\n" + "="*50)
    print("YOLO EÄÄ°TÄ°M ARACI - CHECKPOINT MODU (V28)")
    print("="*50)
    
    # 1. Model SeÃ§imi (CLI veya interaktif)
    if args.model:
        model_name = args.model
        print(f"ğŸ“¦ Model (CLI): {model_name}")
    else:
        model_name = select_model_menu()
    pt_file = f"{model_name}.pt"
    
    # 2. Checkpoint Listesi (CLI veya interaktif)
    if args.checkpoints:
        checkpoints = [int(x.strip()) for x in args.checkpoints.split(',')]
        print(f"ğŸ¯ Checkpoints (CLI): {checkpoints}")
    else:
        print("\nğŸ“‹ Checkpoint epoch'larÄ±nÄ± virgÃ¼lle girin")
        print("   Ã–rnek: 25,50,100,200")
        checkpoint_input = input("Checkpoints: ").strip()
        try:
            checkpoints = [int(x.strip()) for x in checkpoint_input.split(',')]
        except:
            print("âŒ GeÃ§ersiz giriÅŸ, varsayÄ±lan kullanÄ±lÄ±yor: [25, 50, 100]")
            checkpoints = [25, 50, 100]
    
    # Checkpoint'leri sÄ±rala
    checkpoints = sorted(set(checkpoints))
    
    # 3. Mod SeÃ§imi (CLI veya interaktif)
    if args.overwrite:
        action = "OVERWRITE"
    else:
        print("\n[R]esume (Devam Et) | [O]verwrite (SÄ±fÄ±rla)")
        mode = input("SeÃ§im [R/o]: ").strip().upper()
        action = "OVERWRITE" if mode == 'O' else "RESUME"

    # YollarÄ± belirle
    run_dir = Path("runs/detect") / model_name
    last_pt = run_dir / "weights" / "last.pt"
    
    workers = cfg.workers
    current_epoch = 0
    
    if action == "OVERWRITE":
        if run_dir.exists():
            try: shutil.rmtree(run_dir)
            except: pass
            print("ğŸ§¹ Eski eÄŸitim klasÃ¶rÃ¼ silindi.")
        current_weights = pt_file
        current_epoch = 0
    else:
        if last_pt.exists():
            current_epoch = get_current_epoch(last_pt)
            print(f"ğŸ”„ KaldÄ±ÄŸÄ± yer tespit edildi: Epoch {current_epoch}")
            current_weights = str(last_pt)
            force_patch_workers(last_pt)
        else:
            print("âš ï¸ KayÄ±tlÄ± model bulunamadÄ±, sÄ±fÄ±rdan baÅŸlanÄ±yor...")
            current_weights = pt_file
            current_epoch = 0
    
    # Zaten tamamlanmÄ±ÅŸ checkpoint'leri atla
    remaining_checkpoints = [cp for cp in checkpoints if cp > current_epoch]
    
    if not remaining_checkpoints:
        print(f"\nâœ… TÃ¼m checkpoint'ler zaten tamamlanmÄ±ÅŸ! (Mevcut: {current_epoch})")
        return
    
    print(f"\n{'='*50}")
    print(f"ğŸš€ EÄÄ°TÄ°M PLANI")
    print(f"{'='*50}")
    print(f"ğŸ“¦ Model: {model_name.upper()}")
    print(f"ğŸ“ BaÅŸlangÄ±Ã§ Epoch: {current_epoch}")
    print(f"ğŸ¯ Checkpoints: {remaining_checkpoints}")
    print(f"ğŸ Final Epoch: {remaining_checkpoints[-1]}")
    print(f"âš¡ Ayarlar: Cache={cfg.cache_images}, Workers={workers}, Batch={cfg.batch_size}")
    
    input("\nğŸ‘‰ BaÅŸlamak iÃ§in ENTER...")
    
    if os.name == 'nt':
        torch.multiprocessing.set_sharing_strategy('file_system')

    gc.collect()
    torch.cuda.empty_cache()
    
    overall_start_time = time.time()
    
    try:
        # Model yÃ¼kle
        print(f"\nğŸ“¥ Model yÃ¼kleniyor: {current_weights}...")
        try:
            model = YOLO(current_weights)
        except Exception as e:
            print(f"\nâŒ HATA: Model dosyasÄ± '{current_weights}' bulunamadÄ± veya indirilemedi.")
            print(f"ğŸ›‘ Teknik Detay: {e}")
            sys.exit(1)

        # Her checkpoint iÃ§in eÄŸit ve rapor oluÅŸtur
        is_first_run = (current_epoch == 0)
        
        for i, target_epoch in enumerate(remaining_checkpoints):
            checkpoint_start_time = time.time()
            
            print(f"\n{'#'*50}")
            print(f"# CHECKPOINT {i+1}/{len(remaining_checkpoints)}: Epoch {target_epoch}")
            print(f"{'#'*50}")
            
            # EÄŸit
            train_to_checkpoint(model, yaml_path, cfg, model_name, target_epoch, workers, is_first_run)
            
            # Validation ve rapor
            final_last_pt = run_dir / "weights" / "last.pt"
            if final_last_pt.exists():
                checkpoint_duration = (time.time() - checkpoint_start_time) / 60.0
                total_duration = (time.time() - overall_start_time) / 60.0
                
                run_validation_and_report(
                    final_last_pt, yaml_path, cfg, model_name, 
                    target_epoch, result_dir, ckpt_dir, total_duration
                )
                
                # Modeli tekrar yÃ¼kle (resume iÃ§in)
                del model
                gc.collect()
                torch.cuda.empty_cache()
                model = YOLO(str(final_last_pt))
            
            is_first_run = False  # ArtÄ±k resume modunda
            print(f"\nâœ… Checkpoint {target_epoch} tamamlandÄ±! ({checkpoint_duration:.1f} dk)")
        
        # Final Ã¶zet
        total_duration = (time.time() - overall_start_time) / 60.0
        print(f"\n{'='*50}")
        print(f"ğŸ‰ TÃœM CHECKPOINTS TAMAMLANDI!")
        print(f"{'='*50}")
        print(f"â±ï¸ Toplam SÃ¼re: {total_duration:.1f} dakika ({total_duration/60:.2f} saat)")
        print(f"ğŸ“Š Raporlar: {result_dir / 'reports'}")
        print(f"ğŸ’¾ Modeller: {ckpt_dir}")

    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ EÄŸitim kullanÄ±cÄ± tarafÄ±ndan durduruldu!")
        print(f"ğŸ’¡ Devam etmek iÃ§in: python train.py --checkpoints {','.join(map(str, remaining_checkpoints))}")
    except Exception as e:
        print(f"\nâŒ BEKLENMEYEN HATA: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
